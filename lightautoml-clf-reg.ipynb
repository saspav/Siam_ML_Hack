{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10920730,"sourceType":"datasetVersion","datasetId":6789423}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from time import time\n\n__import__(\"warnings\").filterwarnings('ignore')\n\nglobal_time = time()\nglobal_time_stop = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T17:50:21.648011Z","iopub.execute_input":"2025-03-04T17:50:21.648218Z","iopub.status.idle":"2025-03-04T17:50:21.652964Z","shell.execute_reply.started":"2025-03-04T17:50:21.648196Z","shell.execute_reply":"2025-03-04T17:50:21.651932Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-04T17:50:21.653940Z","iopub.execute_input":"2025-03-04T17:50:21.654200Z","iopub.status.idle":"2025-03-04T17:50:23.034741Z","shell.execute_reply.started":"2025-03-04T17:50:21.654172Z","shell.execute_reply":"2025-03-04T17:50:23.033296Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hackathon-2025/aggregate_data_files_log10.pkl\n/kaggle/input/hackathon-2025/preprocess_files_log10.pkl\n/kaggle/input/hackathon-2025/aggregate_data_files_no_log.pkl\n/kaggle/input/hackathon-2025/preprocess_files_no_log.pkl\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install tqdm_joblib -q\n!pip install transformers==4.47.0 -q\n!pip install category-encoders==2.8.0 -q\n!pip install scikit-learn==1.6.0 -q\n!pip install catboost==1.2.7 -q\n!pip install featuretools==1.31.0 -q\n!pip install matplotlib==3.8.3 -q\n!pip install optuna==4.1.0 -q\n!pip install optuna-integration==4.1.0 -q\n!pip install LightAutoML==0.4.0 -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T17:50:23.036074Z","iopub.execute_input":"2025-03-04T17:50:23.036588Z","iopub.status.idle":"2025-03-04T17:51:43.020342Z","shell.execute_reply.started":"2025-03-04T17:50:23.036558Z","shell.execute_reply":"2025-03-04T17:51:43.019290Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.6/399.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.0/216.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Building wheel for json2html (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Скачиваем дополнительные модули из репо\n!wget -q https://raw.githubusercontent.com/saspav/DFC-2025/main/df_addons.py > /dev/null 2>&1\n!wget -q https://raw.githubusercontent.com/saspav/DFC-2025/main/print_time.py > /dev/null 2>&1\n!wget -q https://raw.githubusercontent.com/saspav/DFC-2025/main/set_all_seeds.py > /dev/null 2>&1\n!wget -q https://raw.githubusercontent.com/saspav/DFC-2025/main/data_process_sml.py > /dev/null 2>&1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T17:51:43.022496Z","iopub.execute_input":"2025-03-04T17:51:43.022750Z","iopub.status.idle":"2025-03-04T17:51:45.709422Z","shell.execute_reply.started":"2025-03-04T17:51:43.022713Z","shell.execute_reply":"2025-03-04T17:51:45.708139Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport copy\nimport joblib\n\nfrom pathlib import Path\n\n# LightAutoML presets, task and report generation\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n# from lightautoml.automl.presets.whitebox_presets import WhiteBoxPreset\nfrom lightautoml.tasks import Task\nfrom lightautoml.report.report_deco import ReportDeco\n\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nfrom sklearn.metrics import r2_score, mean_squared_error, explained_variance_score\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error\n\nfrom data_process_sml import (RANDOM_SEED, PREDICTIONS_DIR, MODEL_PATH, get_max_num,\n                              add_info_to_log, DataTransform)\n\nfrom print_time import print_time, print_msg\n\nfrom set_all_seeds import set_all_seeds\n\n__import__(\"warnings\").filterwarnings('ignore')\n\nset_all_seeds(seed=RANDOM_SEED)\n\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nDATASET_PATH = Path('/kaggle/input/hackathon-2025')\n\nWORK_PATH = Path('.')\nMODELS_LOGS = WORK_PATH.joinpath('scores.logs')\nMODELS_LOGS_REG = WORK_PATH.joinpath('scores_reg.logs')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T17:51:45.711081Z","iopub.execute_input":"2025-03-04T17:51:45.711374Z","iopub.status.idle":"2025-03-04T17:52:43.189607Z","shell.execute_reply.started":"2025-03-04T17:51:45.711330Z","shell.execute_reply":"2025-03-04T17:52:43.188098Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"DATASET_PATH, PREDICTIONS_DIR, MODEL_PATH","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T17:52:43.190861Z","iopub.execute_input":"2025-03-04T17:52:43.191736Z","iopub.status.idle":"2025-03-04T17:52:43.199435Z","shell.execute_reply.started":"2025-03-04T17:52:43.191701Z","shell.execute_reply":"2025-03-04T17:52:43.198435Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(PosixPath('/kaggle/input/hackathon-2025'),\n PosixPath('predictions'),\n PosixPath('models'))"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T17:52:43.200225Z","iopub.execute_input":"2025-03-04T17:52:43.200476Z","iopub.status.idle":"2025-03-04T17:52:43.236427Z","shell.execute_reply.started":"2025-03-04T17:52:43.200455Z","shell.execute_reply":"2025-03-04T17:52:43.235588Z"}},"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def acc_score(y_true, y_pred, **kwargs):\n    return accuracy_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\n\ndef f1_metric(y_true, y_pred, **kwargs):\n    return f1_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n    \n\nstart_time = print_msg('Обучение TabularAutoML ...')\n\nmax_num_bin = get_max_num(log_file=MODELS_LOGS) + 1\nmax_num_reg = get_max_num(log_file=MODELS_LOGS_REG) + 1\n\nsub_pref = 'kla_'\n\nnumeric_columns = []\n\nbinary_targets = ['Некачественное ГДИС', 'Влияние ствола скважины', 'Радиальный режим',\n                  'Линейный режим', 'Билинейный режим', 'Сферический режим',\n                  'Граница постоянного давления', 'Граница непроницаемый разлом']\n\nnumeric_targets = ['Влияние ствола скважины_details', 'Радиальный режим_details',\n                   'Линейный режим_details', 'Билинейный режим_details',\n                   'Сферический режим_details', 'Граница постоянного давления_details',\n                   'Граница непроницаемый разлом_details']\n\n# binary_targets = [clean_column_name(col) for col in binary_targets]\n\ncat_columns = []\n\n# Чтение и предобработка данных\ndata_cls = DataTransform(use_catboost=True,\n                         category_columns=cat_columns,\n                         drop_first=False,\n                         # numeric_columns=numeric_columns, scaler=StandardScaler,\n                         )\n\n# train_df, test_df = data_cls.make_agg_data(use_featuretools=False,\n#                                            file_with_target_class=None)\n\n# Только ручные признаки\npreprocess_files = DATASET_PATH.joinpath('preprocess_files_log10.pkl')\nwith open(preprocess_files, 'rb') as in_file:\n    train_df, test_df, *_ = joblib.load(in_file)\n\n# # С признаками TSFRESH\n# aggregate_path_file = DATASET_PATH.joinpath('aggregate_data_files_log10.pkl')\n# with open(aggregate_path_file, 'rb') as in_file:\n#     train_df, test_df = joblib.load(in_file)\n\n# train_df = train_df.sample(n=300, random_state=RANDOM_SEED)\n\n# # Добавление группировок от таргет-енкодинга\n# train_df = data_cls.fit_transform(train_df)\n# test_df = data_cls.transform(test_df)\n\nfeatures2drop = ['hq', 'labels']\n\nexclude_columns = ['count_rows',\n                   ]\n\n# exclude_columns = [clean_column_name(col) for col in exclude_columns]\n\nexclude_columns.extend(data_cls.exclude_columns)\n\nmodel_columns = test_df.columns.to_list()\n\n# Добавим в категориальные признаки те, что были посчитаны как мода\ncat_columns.extend([col for col in model_columns if col.upper().startswith('MODE_')])\n\nmodel_columns = [col for col in model_columns if col not in exclude_columns]\ncat_columns = [col for col in cat_columns if col in model_columns]\n\nexclude_columns = features2drop + exclude_columns\n\nprint('Обучаюсь на колонках:', model_columns)\nprint('Категорийные колонки:', cat_columns)\nprint('Исключенные колонки:', exclude_columns)\n\nprint(f'Размер train_df = {train_df.shape}, test = {test_df.shape}')\n\ntrain = train_df[model_columns].drop(columns=features2drop, errors='ignore')\ntarget = train_df[binary_targets + numeric_targets]\ntest_df = test_df[model_columns].copy()\n\nprint('train.shape', train.shape, 'пропусков:', train.isna().sum().sum())\nprint('test.shape', test_df.drop(columns=features2drop, errors='ignore').shape,\n      'пропусков:', test_df.isna().sum().sum())\n\n# set initial runtime rate guess for first level models\n_time_scores = {\n    \"lgb\": 1,\n    \"lgb_tuned\": 3,\n    \"xgb\": 1,\n    \"xgb_tuned\": 3,\n    \"linear_l2\": 0.7,\n    \"cb\": 2,\n    \"cb_tuned\": 6,\n    \"rf\": 5,\n    \"rf_tuned\": 10,\n    \"nn\": 10,\n    \"nn_tuned\": 20,\n}\n\nN_THREADS = 4  # threads cnt for lgbm and linear models\nG_MEMORY = 24  # \nN_FOLDS = 5  # folds cnt for AutoML\nTEST_SIZE = 0.2  # Test size for metric check\nTIMEOUT = 60 * 45  # Time in seconds for automl run","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T17:52:43.237225Z","iopub.execute_input":"2025-03-04T17:52:43.237535Z","iopub.status.idle":"2025-03-04T17:52:47.251207Z","shell.execute_reply.started":"2025-03-04T17:52:43.237505Z","shell.execute_reply":"2025-03-04T17:52:47.249496Z"}},"outputs":[{"name":"stdout","text":"Обучение TabularAutoML ...\nОбучаюсь на колонках: ['dP_mean', 'dP_median', 'dP_std', 'Pder_mean', 'Pder_median', 'Pder_std', 'wb_present', 'wb_b', 'ra_present', 'ra_b', 'li_present', 'li_b', 'bi_present', 'bi_b', 'sp_present', 'sp_b', 'pc_time', 'im_time']\nКатегорийные колонки: []\nИсключенные колонки: ['hq', 'labels', 'count_rows']\nРазмер train_df = (45141, 38), test = (500, 19)\ntrain.shape (45141, 18) пропусков: 0\ntest.shape (500, 18) пропусков: 0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"full_submit = pd.DataFrame(index=test_df.index)\nmodels_scores = []\nmodels_to_save = []\n\nfor idx_target, one_target in enumerate(binary_targets + numeric_targets):\n\n    train_with_target = train.join(target[one_target], how=\"left\")\n\n    binary_task = True\n    if idx_target > 7:\n        binary_task = False\n\n    if binary_task:\n        # Available metrics for binary task:\n        # ‘auc’ - (uses by default) ROC-AUC score.\n        # ‘accuracy’ - Accuracy score (uses argmax prediction).\n        # ‘logloss’ - Standard logistic loss.\n        task = Task('binary', metric='auc')\n    else:\n        # Avaliable losses & metrics for regression task:\n        # ‘mse’ - (uses by default) Mean Squared Error.\n        # ‘mae’ - Mean Absolute Error.\n        # ‘mape’ - Mean Absolute Percentage Error.\n        # ‘rmsle’ - Root Mean Squared Log Error.\n        task = Task('reg', loss='mse', metric='mse')\n\n    roles = {'target': one_target,\n             }\n\n    RD = ReportDeco(output_path='tabularAutoML_model_report')\n\n    # Настройка автоматической модели\n    automl = TabularAutoML(task=task,\n                           timeout=TIMEOUT,\n                           cpu_limit=N_THREADS,\n                           memory_limit=G_MEMORY,\n                           general_params={\n                               # 'use_algos': [[\n                               #     'rf',\n                               #     'lgb',\n                               #     'lgb_tuned',\n                               #     'cb_tuned',\n                               #     # 'linear_l2',\n                               #     'xgb_tuned',\n                               # ],\n                               #     [\n                               #         'cb_tuned',\n                               #         # 'rf',\n                               #         # 'linear_l2',\n                               #     ],\n                               # ],\n\n                               'use_algos': 'auto',\n\n                               # 'use_algos': [[\n                               #     'rf',\n                               #     'lgb',\n                               #     'cb', ],\n                               # ],\n\n                               'tuning_params': {\n                                   # Время для подбора гиперпараметров (в секундах)\n                                   'max_tuning_time': 60 * 12,\n                                   # Максимальное количество итераций подбора\n                                   'max_tuning_iter': 88,\n                               },                               \n\n                               # 'custom_params': custom_params,\n                           },\n                           reader_params={'n_jobs': N_THREADS,\n                                          'cv': N_FOLDS,\n                                          'random_state': RANDOM_SEED},\n                           )\n\n    # automl = RD(automl)\n\n    oof_pred = automl.fit_predict(train_with_target, roles=roles, verbose=1)\n    valid_proba = oof_pred.data[:, 0]\n\n    print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:7], oof_pred.shape))\n\n    test_pred = automl.predict(test_df)\n    predict_test = test_pred.data[:, 0]\n\n    models_to_save.append(automl)\n\n    print('Check scores...')\n\n    y_valid = train_with_target[one_target].values\n\n    if binary_task:\n        predict_valid = (valid_proba >= 0.5).astype(int)\n        predict_test = (predict_test >= 0.5).astype(int)\n        model_score = acc_score(y_valid, valid_proba)\n    else:\n        # Заменяем значения меньше -33 на 0, т.к. пропуски были заполнены -99\n        y_valid[y_valid < -33] = 0\n        valid_proba[valid_proba < -33] = 0\n        model_score = mean_squared_error(y_valid, valid_proba)\n\n    print('OOF score: {}'.format(model_score))\n\n    submission = test_df[test_df.columns.to_list()[:2]].copy()\n    submission[one_target] = predict_test\n    full_submit[one_target] = predict_test\n\n    # Сохранение предсказаний в файл\n    max_num = max_num_bin\n    post_fix = ''\n    if not binary_task:\n        post_fix = '_reg'\n        max_num = max_num_reg\n    submit_csv = f'{sub_pref}submit_{max_num:03}_target{idx_target}{post_fix}.csv'\n\n    submission[[one_target]].to_csv(PREDICTIONS_DIR.joinpath(submit_csv))\n\n    if idx_target == 7:\n        # Сохранение предсказаний в файл\n        submit_csv = f'{sub_pref}submit_{max_num:03}.csv'\n        full_submit.to_csv(PREDICTIONS_DIR.joinpath(submit_csv))\n\n    print(automl.create_model_str_desc())\n\n    info_cols = (model_columns, exclude_columns, cat_columns)\n\n    save_time = print_msg('Сохранение модели ...')\n    save_vodel_file = MODEL_PATH.joinpath(f'automl_{max_num:03}_{idx_target:02}.pkl')\n    with open(save_vodel_file, 'wb') as file:\n        joblib.dump((automl, binary_targets, numeric_targets, info_cols), file,\n                    compress=7)\n    print_time(save_time)\n\n    comment = {}\n    comment.update({'SEED': RANDOM_SEED,\n                    'target': one_target,\n                    })\n\n    t_score = f1_macro = f1_micro = f1_wght = 0\n    if binary_task:\n        # Для многоклассового ROC AUC, нужно указать multi_class\n        auc_macro = roc_auc_score(y_valid, valid_proba, average='macro')\n        auc_micro = roc_auc_score(y_valid, valid_proba, average='micro')\n        auc_wght = roc_auc_score(y_valid, valid_proba, average='weighted')\n        try:\n            f1_macro = f1_score(y_valid, predict_valid, average='macro')\n            f1_micro = f1_score(y_valid, predict_valid, average='micro')\n            f1_wght = f1_score(y_valid, predict_valid, average='weighted')\n        except:\n            pass\n    else:\n        auc_macro = mean_squared_error(y_valid, predict_valid) ** 0.5\n        # Mean Absolute Error: среднее абсолютное отклонение предсказанных значений от фактических\n        auc_micro = mean_absolute_error(y_valid, predict_valid)\n        # Mean Squared Error: средний квадрат отклонений предсказаний от фактических значений\n        auc_wght = mean_squared_error(y_valid, predict_valid)\n        # R² Score показывает, какую долю вариации зависимой переменной объясняет модель. Значение\n        # R² варьируется от 0 до 1 (или может быть отрицательным, если модель плоха).\n        # Значение 1 говорит о том, что модель идеально подходит к данным.\n        f1_macro = r2_score(y_valid, predict_valid)\n        # Explained Variance Score: метрика показывает долю вариации целевой переменной, которую\n        # может объяснить модель. Значение равно 1, если модель идеально объясняет данные, и\n        # 0, если модель не способна предсказать значение лучше, чем просто использовать среднее\n        # значение целевой переменной.\n        f1_wght = explained_variance_score(y_valid, predict_valid)\n        # Mean Squared Logarithmic Error: измеряет среднюю разницу между логарифмами предсказанных\n        # и фактических значений. Это полезно в случаях, когда хотим уменьшить влияние больших\n        # ошибок, особенно при работе с экспоненциально растущими данными.\n        # Заменяем значения меньше нуля на 0\n        try:\n            y_valid[y_valid < 0] = 0\n            predict_valid[predict_valid < 0] = 0\n            f1_micro = mean_squared_log_error(y_valid, predict_valid)\n        except:\n            pass\n\n    valid_scores = (model_score, auc_macro, auc_micro, auc_wght,\n                    f1_macro, f1_micro, f1_wght, t_score)\n\n    models_scores.append(valid_scores)\n\n    if binary_task:\n        add_info_to_log(f'{sub_pref}{idx_target}_', max_num_bin, 0, None, valid_scores,\n                        info_cols, comment, log_file=MODELS_LOGS)\n    else:\n        add_info_to_log(f'{sub_pref}{idx_target}_', max_num_reg, 0, None, valid_scores,\n                        info_cols, comment, log_file=MODELS_LOGS_REG)\n\n# Постпроцессинг: зануляем значения, если binary_targets = 0\nfor target, binary_col in zip(numeric_targets, binary_targets[1:]):\n    full_submit.loc[full_submit[binary_col] == 0, target] = np.nan\n# Сохранение предсказаний в файл\nsubmit_csv = f'{sub_pref}submit_{max_num_reg:03}_reg.csv'\nfull_submit.to_csv(PREDICTIONS_DIR.joinpath(submit_csv))\n\nsave_time = print_msg('Сохранение моделей ...')\nwith open(MODEL_PATH.joinpath(f'automl_{max_num_reg:03}_all.pkl'), 'wb') as file:\n    joblib.dump((models_to_save, binary_targets, numeric_targets, info_cols), file,\n                compress=7)\nprint_time(save_time)\n\ncomment = {}\ncomment.update({'SEED': RANDOM_SEED,\n                'target': f'Кол-во: {len(binary_targets)}',\n                })\n\nvalid_scores = [np.mean(arg) for arg in zip(*models_scores[:8])]\nadd_info_to_log(f'{sub_pref}{idx_target}_', max_num_bin, 0, None, valid_scores,\n                info_cols, comment, log_file=MODELS_LOGS)\n\nvalid_scores = [np.mean(arg) for arg in zip(*models_scores[8:])]\nadd_info_to_log(f'{sub_pref}{idx_target}_', max_num_reg, 0, None, valid_scores,\n                info_cols, comment, log_file=MODELS_LOGS_REG)\n\nprint_time(start_time)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T17:52:47.252610Z","iopub.execute_input":"2025-03-04T17:52:47.252964Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"[17:52:47] Stdout logging level is INFO.\n[17:52:47] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n[17:52:47] Task: binary\n\n[17:52:47] Start automl preset with listed constraints:\n[17:52:47] - time: 2700.00 seconds\n[17:52:47] - CPU: 4 cores\n[17:52:47] - memory: 24 GB\n\n[17:52:47] \u001b[1mTrain data shape: (45141, 19)\u001b[0m\n\n[17:52:53] Layer \u001b[1m1\u001b[0m train process start. Time left 2693.57 secs\n[17:52:55] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[17:52:58] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.656767177914291\u001b[0m\n[17:52:58] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[17:52:58] Time left 2689.25 secs\n\n[17:52:59] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n[17:53:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[17:53:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8542541608000961\u001b[0m\n[17:53:16] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[17:53:16] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n","output_type":"stream"},{"name":"stderr","text":"Optimization Progress:  94%|█████████▍| 95/101 [05:01<00:19,  3.17s/it, best_trial=12, best_value=0.857]","output_type":"stream"},{"name":"stdout","text":"[17:58:17] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[17:58:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"[17:58:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8518587092053268\u001b[0m\n[17:58:27] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[17:58:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[17:59:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8499296233157536\u001b[0m\n[17:59:16] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[17:59:16] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n","output_type":"stream"},{"name":"stderr","text":"Optimization Progress:   0%|          | 0/101 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from IPython.display import display, FileLink\nfrom zipfile import ZipFile, ZIP_DEFLATED as ZD\nfrom glob import glob\n\nfiles = glob(str(MODEL_PATH) + '/*.*') + glob(str(PREDICTIONS_DIR) + '/*.*')\nfiles += glob('tabularAutoML_model_report/*.*') \nfiles += glob('*.logs')\nzip_filename = f'model_lightautoml_clf_reg.zip'\nwith ZipFile(zip_filename, 'w',  compression=ZD, compresslevel=9) as zip_file:\n    for filename in files:\n        print(filename)\n        zip_file.write(filename)\nFileLink(zip_filename)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}